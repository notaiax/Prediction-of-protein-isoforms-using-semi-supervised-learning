{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-LbQC9Wc6dmg"
      },
      "outputs": [],
      "source": [
        "from typing import *\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display, clear_output\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_style(\"whitegrid\")\n",
        "import requests\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn.functional import softplus\n",
        "from torch.distributions import Distribution\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from functools import reduce\n",
        "from torch.distributions.bernoulli import Bernoulli\n",
        "\n",
        "import gzip\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_chunk(filename, chunk_size=1000):\n",
        "    \"\"\" Load a chunk of data from a gzipped TSV file. \"\"\"\n",
        "    return pd.read_csv(filename, sep='\\t', compression='gzip', chunksize=chunk_size)\n",
        "\n",
        "def separate_ids_and_data(data):\n",
        "    ids = data.iloc[:, 0]\n",
        "    data = data.iloc[:, 1:]\n",
        "    return ids, data\n",
        "\n",
        "class ReparameterizedDiagonalGaussian(Distribution):\n",
        "    \"\"\"\n",
        "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
        "    \"\"\"\n",
        "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
        "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
        "        self.mu = mu\n",
        "        self.sigma = log_sigma.exp()\n",
        "\n",
        "    def sample_epsilon(self) -> Tensor:\n",
        "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
        "        return torch.empty_like(self.mu).normal_()\n",
        "\n",
        "    def sample(self) -> Tensor:\n",
        "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
        "        with torch.no_grad():\n",
        "            return self.rsample()\n",
        "\n",
        "    def rsample(self) -> Tensor:\n",
        "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
        "        # z = mu + sigma * epsilon\n",
        "        return self.mu + self.sigma * self.sample_epsilon()\n",
        "\n",
        "    def log_prob(self, z: Tensor) -> Tensor:\n",
        "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
        "        # Log probability for Gaussian distribution\n",
        "        # log p(z) = -1/2 * [log(2*pi) + 2*log(sigma) + (z - mu)^2/sigma^2]\n",
        "        return -0.5 * (torch.log(2 * torch.tensor(math.pi)) + 2 * torch.log(self.sigma) +\n",
        "                       torch.pow(z - self.mu, 2) / torch.pow(self.sigma, 2))\n",
        "    \n",
        "    def count_csv_rows(filename):\n",
        "        # If the file is gzip-compressed, decompress it first\n",
        "        if filename.endswith('.gz'):\n",
        "            with gzip.open(filename, 'rt', newline='') as csvfile:\n",
        "                row_count = sum(1 for row in csvfile)\n",
        "        else:\n",
        "            # Specify the correct encoding (e.g., 'utf-8', 'latin-1', etc.)\n",
        "            encoding = 'utf-8'  # Change to the appropriate encoding if needed\n",
        "            with open(filename, 'r', newline='', encoding=encoding) as csvfile:\n",
        "                row_count = sum(1 for row in csvfile)\n",
        "        return row_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbMPs6aIq267",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKE6MiTPq267",
        "outputId": "a22fa10f-d1fd-473b-bb30-70ddff0601fe",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(18965, 156958)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the file paths\n",
        "archs4_path = \"/dtu-compute/datasets/iso_02456/archs4_gene_expression_norm_transposed.tsv.gz\"\n",
        "gtex_gene_path = \"/dtu-compute/datasets/iso_02456/gtex_gene_expression_norm_transposed.tsv.gz\"\n",
        "gtex_isoform_path = \"/dtu-compute/datasets/iso_02456/gtex_isoform_expression_norm_transposed.tsv.gz\"\n",
        "gtex_anno_path = \"/dtu-compute/datasets/iso_02456/gtex_gene_isoform_annoation.tsv.gz\"\n",
        "gtex_tissue_path = \"/dtu-compute/datasets/iso_02456/gtex_annot.tsv.gz\"\n",
        "\n",
        "num_genes = 18965\n",
        "num_isoforms = 156958\n",
        "\n",
        "num_genes, num_isoforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gtex_gene_path num rows: 17357\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8.6785"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count_csv_rows(gtex_gene_path)\n",
        "print(\"gtex_gene_path num rows: 17357\")\n",
        "percentage_calc = 17357 * 0.0005\n",
        "percentage_calc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using percentage 0.001 should load 17 samples, and 0.01 170. We use 0.005 for 86 samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Label Encoding: This converts each unique label into a unique integer. If you have a large number of classes, be aware of memory usage.\n",
        "- Inverse Transformation: If you need to get back the original labels from the encoded ones, you can use self.label_encoder.inverse_transform().\n",
        "- Data Types: Labels are converted to torch.long since they are now integers, which is a common practice for categorical labels in classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GeneExpressionDataset(Dataset):\n",
        "    \"\"\" # Old dataLoader with no TestSet\n",
        "    def __init__(self, filepath, percentage=0.1):\n",
        "        self.data = self.load_data_percentage(filepath, percentage)\n",
        "        # Assuming the first column is the label\n",
        "        self.labels = self.data.iloc[:, 0]\n",
        "        self.genes = self.data.iloc[:, 1:]\n",
        "\n",
        "        # Encode the labels\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.encoded_labels = self.label_encoder.fit_transform(self.labels)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, labels):\n",
        "        self.labels = labels\n",
        "        self.genes = data\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.encoded_labels = self.label_encoder.fit_transform(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.genes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        label = self.encoded_labels[idx]\n",
        "        genes = self.genes.iloc[idx]\n",
        "        return torch.tensor(genes.values, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    def get_original_labels(self, encoded_labels):\n",
        "        return self.label_encoder.inverse_transform(encoded_labels)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_data_percentage(filepath, percentage=0.1):\n",
        "        # Load a percentage of the data as shown previously\n",
        "        cols = pd.read_csv(filepath, sep='\\t', compression='gzip', nrows=0).columns\n",
        "        n_total_rows = sum(1 for row in open(filepath, 'rb'))\n",
        "        n_rows_to_load = int(n_total_rows * percentage)\n",
        "        skip_rows = np.random.choice(np.arange(1, n_total_rows), size=n_total_rows - n_rows_to_load, replace=False)\n",
        "        return pd.read_csv(filepath, sep='\\t', compression='gzip', usecols=cols, skiprows=skip_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_percentage = 0.0005\n",
        "\n",
        "# Load the entire dataset\n",
        "full_data = GeneExpressionDataset.load_data_percentage(gtex_gene_path, percentage=load_percentage)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(full_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create dataset instances for training and testing\n",
        "gene_train_dataset = GeneExpressionDataset(train_data.iloc[:, 1:], train_data.iloc[:, 0])\n",
        "gene_test_dataset = GeneExpressionDataset(test_data.iloc[:, 1:], test_data.iloc[:, 0])\n",
        "\n",
        "gene_train_loader = DataLoader(gene_train_dataset, batch_size=64, shuffle=True)\n",
        "gene_test_loader = DataLoader(gene_test_dataset, batch_size=64, shuffle=False)  # Usually, shuffling is not needed for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>TMEM38B</th>\n",
              "      <th>SLC24A3</th>\n",
              "      <th>AXDND1</th>\n",
              "      <th>DUXA</th>\n",
              "      <th>ZCCHC13</th>\n",
              "      <th>FGF18</th>\n",
              "      <th>INPP5D</th>\n",
              "      <th>MAP2K4</th>\n",
              "      <th>BCAR1</th>\n",
              "      <th>...</th>\n",
              "      <th>MARCH10</th>\n",
              "      <th>EVL</th>\n",
              "      <th>CYP1A2</th>\n",
              "      <th>ZNF782</th>\n",
              "      <th>LIMCH1</th>\n",
              "      <th>WDR24</th>\n",
              "      <th>ANGPTL4</th>\n",
              "      <th>UGT2B7</th>\n",
              "      <th>PIPOX</th>\n",
              "      <th>CD1B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GTEX-11OC5-0526-SM-5N9EE</td>\n",
              "      <td>2.073820</td>\n",
              "      <td>0.903038</td>\n",
              "      <td>0.275007</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.025029</td>\n",
              "      <td>5.518850</td>\n",
              "      <td>3.590961</td>\n",
              "      <td>5.004951</td>\n",
              "      <td>...</td>\n",
              "      <td>2.232661</td>\n",
              "      <td>6.223036</td>\n",
              "      <td>0.014355</td>\n",
              "      <td>1.819668</td>\n",
              "      <td>5.989366</td>\n",
              "      <td>3.499527</td>\n",
              "      <td>3.705978</td>\n",
              "      <td>0.042644</td>\n",
              "      <td>0.910733</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GTEX-14BIM-0011-R4b-SM-5S2RK</td>\n",
              "      <td>1.871844</td>\n",
              "      <td>3.390943</td>\n",
              "      <td>0.263034</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.321928</td>\n",
              "      <td>2.935460</td>\n",
              "      <td>3.970854</td>\n",
              "      <td>4.031219</td>\n",
              "      <td>...</td>\n",
              "      <td>1.021480</td>\n",
              "      <td>7.375300</td>\n",
              "      <td>0.028569</td>\n",
              "      <td>0.739848</td>\n",
              "      <td>3.771886</td>\n",
              "      <td>2.295723</td>\n",
              "      <td>4.958379</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.333424</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GTEX-1F75A-0011-R7b-SM-9QEHE</td>\n",
              "      <td>1.778209</td>\n",
              "      <td>3.820690</td>\n",
              "      <td>0.250962</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.176323</td>\n",
              "      <td>2.157044</td>\n",
              "      <td>4.173927</td>\n",
              "      <td>4.626439</td>\n",
              "      <td>...</td>\n",
              "      <td>2.130931</td>\n",
              "      <td>7.749333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.871844</td>\n",
              "      <td>4.730096</td>\n",
              "      <td>2.769772</td>\n",
              "      <td>3.510962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.099295</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GTEX-1HBPM-2626-SM-9WYU5</td>\n",
              "      <td>2.687061</td>\n",
              "      <td>3.663345</td>\n",
              "      <td>0.344828</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.389567</td>\n",
              "      <td>3.237258</td>\n",
              "      <td>3.339137</td>\n",
              "      <td>4.860963</td>\n",
              "      <td>...</td>\n",
              "      <td>1.344828</td>\n",
              "      <td>6.072106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.526069</td>\n",
              "      <td>3.952334</td>\n",
              "      <td>3.085765</td>\n",
              "      <td>4.988230</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.117695</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GTEX-Q2AI-0226-SM-48U1D</td>\n",
              "      <td>3.218781</td>\n",
              "      <td>1.827819</td>\n",
              "      <td>0.669027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.137504</td>\n",
              "      <td>1.735522</td>\n",
              "      <td>3.575312</td>\n",
              "      <td>4.532317</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111031</td>\n",
              "      <td>5.329841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.028569</td>\n",
              "      <td>4.800123</td>\n",
              "      <td>3.431623</td>\n",
              "      <td>2.577731</td>\n",
              "      <td>0.042644</td>\n",
              "      <td>0.485427</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GTEX-ZDTS-1226-SM-4WKGL</td>\n",
              "      <td>3.593354</td>\n",
              "      <td>0.443607</td>\n",
              "      <td>0.495695</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.378512</td>\n",
              "      <td>1.863938</td>\n",
              "      <td>2.742006</td>\n",
              "      <td>5.080231</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.884354</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704872</td>\n",
              "      <td>5.429281</td>\n",
              "      <td>2.510962</td>\n",
              "      <td>2.641546</td>\n",
              "      <td>0.042644</td>\n",
              "      <td>0.097611</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows Ã— 18966 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      sample_id   TMEM38B   SLC24A3    AXDND1  DUXA  ZCCHC13  \\\n",
              "0      GTEX-11OC5-0526-SM-5N9EE  2.073820  0.903038  0.275007     0        0   \n",
              "1  GTEX-14BIM-0011-R4b-SM-5S2RK  1.871844  3.390943  0.263034     0        0   \n",
              "2  GTEX-1F75A-0011-R7b-SM-9QEHE  1.778209  3.820690  0.250962     0        0   \n",
              "3      GTEX-1HBPM-2626-SM-9WYU5  2.687061  3.663345  0.344828     0        0   \n",
              "4       GTEX-Q2AI-0226-SM-48U1D  3.218781  1.827819  0.669027     0        0   \n",
              "5       GTEX-ZDTS-1226-SM-4WKGL  3.593354  0.443607  0.495695     0        0   \n",
              "\n",
              "      FGF18    INPP5D    MAP2K4     BCAR1  ...   MARCH10       EVL    CYP1A2  \\\n",
              "0  2.025029  5.518850  3.590961  5.004951  ...  2.232661  6.223036  0.014355   \n",
              "1  0.321928  2.935460  3.970854  4.031219  ...  1.021480  7.375300  0.028569   \n",
              "2  0.176323  2.157044  4.173927  4.626439  ...  2.130931  7.749333  0.000000   \n",
              "3  0.389567  3.237258  3.339137  4.860963  ...  1.344828  6.072106  0.000000   \n",
              "4  0.137504  1.735522  3.575312  4.532317  ...  0.111031  5.329841  0.000000   \n",
              "5  1.378512  1.863938  2.742006  5.080231  ...  0.000000  5.884354  0.000000   \n",
              "\n",
              "     ZNF782    LIMCH1     WDR24   ANGPTL4    UGT2B7     PIPOX  CD1B  \n",
              "0  1.819668  5.989366  3.499527  3.705978  0.042644  0.910733     0  \n",
              "1  0.739848  3.771886  2.295723  4.958379  0.000000  2.333424     0  \n",
              "2  0.871844  4.730096  2.769772  3.510962  0.000000  3.099295     0  \n",
              "3  1.526069  3.952334  3.085765  4.988230  0.000000  2.117695     0  \n",
              "4  1.028569  4.800123  3.431623  2.577731  0.042644  0.485427     0  \n",
              "5  0.704872  5.429281  2.510962  2.641546  0.042644  0.097611     0  \n",
              "\n",
              "[6 rows x 18966 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "full_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[2.6871, 3.6633, 0.3448,  ..., 0.0000, 2.1177, 0.0000],\n",
              "         [3.5934, 0.4436, 0.4957,  ..., 0.0426, 0.0976, 0.0000],\n",
              "         [1.7782, 3.8207, 0.2510,  ..., 0.0000, 3.0993, 0.0000],\n",
              "         [3.2188, 1.8278, 0.6690,  ..., 0.0426, 0.4854, 0.0000]]),\n",
              " tensor([1, 3, 0, 2]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "genes, labels = next(iter(gene_train_loader))\n",
        "genes, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[2.0738, 0.9030, 0.2750,  ..., 0.0426, 0.9107, 0.0000],\n",
              "         [1.8718, 3.3909, 0.2630,  ..., 0.0000, 2.3334, 0.0000]]),\n",
              " tensor([0, 1]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_genes, test_labels = next(iter(gene_test_loader))\n",
        "test_genes, test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get original labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['GTEX-1HBPM-2626-SM-9WYU5', 'GTEX-ZDTS-1226-SM-4WKGL',\n",
              "       'GTEX-1F75A-0011-R7b-SM-9QEHE', 'GTEX-Q2AI-0226-SM-48U1D'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert encoded labels back to original string labels\n",
        "original_labels = gene_train_dataset.get_original_labels(labels.numpy())\n",
        "original_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Todo: Add code to load VAE or latent features outputed from the VAE for gtex_gene_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DuRG3tVq268",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Building the model\n",
        "When defining the model the latent layer must act as a bottleneck of information, so that we ensure that we find a strong internal representation. We initialize the VAE with 1 hidden layer in the encoder and decoder using relu units as non-linearity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5NZoEyq269",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "### Initialize the model, evaluator and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.2+cu102\n",
            "10.2\n",
            ">> Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\">> Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = gene_train_loader\n",
        "test_loader = gene_test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
